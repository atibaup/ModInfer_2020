
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Tema 3: Estimació &#8212; 104392 - Modelització i Inferència 2020.08.04 documentation</title>
    <link rel="stylesheet" href="../_static/sab-book.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="3. Tema 2: Introducció a l’inferència estadística" href="0_2_Intro_stats.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="0_2_Intro_stats.html" title="3. Tema 2: Introducció a l’inferència estadística"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">104392 - Modelització i Inferència 2020.08.04 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">4. </span>Tema 3: Estimació</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="tema-3-estimacio">
<h1><span class="section-number">4. </span>Tema 3: Estimació<a class="headerlink" href="#tema-3-estimacio" title="Permalink to this headline">¶</a></h1>
<div class="section" id="estimacio-per-maxima-versemblanca">
<h2><span class="section-number">4.1. </span>Estimació per Màxima Versemblança<a class="headerlink" href="#estimacio-per-maxima-versemblanca" title="Permalink to this headline">¶</a></h2>
<div class="section" id="ajust-de-distribucions-de-probabilitat">
<h3><span class="section-number">4.1.1. </span>Ajust de distribucions de probabilitat<a class="headerlink" href="#ajust-de-distribucions-de-probabilitat" title="Permalink to this headline">¶</a></h3>
<p>Recordem de l’exemple que <a class="reference external" href="https://e-aules.uab.cat/2020-21/pluginfile.php/695686/mod_page/content/2/motivacio_tema_3.pdf">vam veure
a la primera classe</a>
que en molts problemes de modelització estadística,
partim d’un conjunt de dades que podem modelar com
una mostra iid. d’una població:</p>
<p><span class="math notranslate nohighlight">\(X_i \sim f_X(x,\theta), i=1,\cdots,N\)</span></p>
<p>on <span class="math notranslate nohighlight">\(f_X\)</span> és una f.d.p. d’una família de distribucions
i <span class="math notranslate nohighlight">\(\theta\)</span> són els paràmetres de la mateixa (vector o escalar), també anomenats
<em>paràmetres de la població</em>.</p>
<p class="note">El problema d’<em>estimació dels paramètres</em> o d’<em>ajust de la distribució</em> a partir de les dades
consisteix en estimar <span class="math notranslate nohighlight">\(\theta\)</span> a partir de <span class="math notranslate nohighlight">\(X_1, \cdots, X_N\)</span>.</p>
<p>Tal i com vam veure a la primera classe, un mètode
d’estimació molt versàtil és el de <strong>Màxima Versemblança</strong>.</p>
<p>Per començar, definim la <em>log-versemblança</em>:</p>
<div class="math notranslate nohighlight">
\[L(\theta; x_1, \cdots, x_N) = \log \left(f_{X_1, \cdots, X_N}(x_1, \cdots, x_N; \theta) \right)\]</div>
<p>on <span class="math notranslate nohighlight">\(f_{X_1, \cdots, X_N}(x_1, \cdots, x_N; \theta)\)</span> és la
f.d.p. conjunta de la mostra.</p>
<p>En el cas d’una mostra iid, la log-versemblança es simplifica:</p>
<div class="math notranslate nohighlight">
\[L(\theta; x_1, \cdots, x_N) = \sum_{i=1}^N \log f_X(x_i;\theta)\]</div>
<p class="note">Per mostres discretes, la log-versemblança es calcula a partir de la f.m.p. conjunta <span class="math notranslate nohighlight">\(p_{X_1, \cdots, X_N}(x_1, \cdots, x_N; \theta)\)</span>
enlloc de la f.d.c.</p>
<p><a href="#id1"><span class="problematic" id="id2">`</span></a></p>
<p>Fixeu-vos que donada una mostra en particular <span class="math notranslate nohighlight">\(X_1=x_1, \cdots, X_N=x_n\)</span>,
<span class="math notranslate nohighlight">\(L(\theta; x_1, \cdots, x_N)\)</span> és un funció de <span class="math notranslate nohighlight">\(\theta \in \Theta \to \mathbb{R}\)</span>.</p>
<p>Com vam veure als exemples de la primera classe, aquesta funció es pot interpretar com una mesura de la
qualitat de <span class="math notranslate nohighlight">\(\theta\)</span> a l’hora d’<em>explicar</em> les dades
observades.</p>
<p>Per tant, sembla raonable definir un estimador del(s)
paràmetre(s) <span class="math notranslate nohighlight">\(\theta\)</span> com:</p>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \arg \max L(\theta; x_1, \cdots, x_N)\]</div>
<p>Aquest és el que s’anomena <strong>Estimador de Màxima Versemblança</strong> (EMV) o MLE per les
seves sigles en anglès.</p>
</div>
<div class="section" id="calcul-de-l-emv">
<h3><span class="section-number">4.1.2. </span>Càlcul de l’EMV<a class="headerlink" href="#calcul-de-l-emv" title="Permalink to this headline">¶</a></h3>
<p>En alguns casos, l’EMV es pot calcular
analíticament, resolent el problema d’optimització associat.
Per exemple en una mostra d’una família Gaussiana,</p>
<div class="math notranslate nohighlight">
\[L(\mu, \sigma; x_1, \cdots, x_N) = - \sum_{i=1}^N \frac{(x_i - \mu)^2}{2\sigma^2} - N \log(\sqrt{2 \pi} \sigma)\]</div>
<p>Aquesta funció és diferenciable i concava en <span class="math notranslate nohighlight">\(\mu\)</span> i  <span class="math notranslate nohighlight">\(\sigma\)</span>,
per tant el seu màxim existeix i haurà de verificar la <strong>condició d’optimalitat</strong>:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\mu, \sigma} L(\mu, \sigma; x_1, \cdots, x_N) = 0\]</div>
<p>Això ens porta a un sistema d’equacions:</p>
<div class="math notranslate nohighlight">
\[\begin{split}- \sum_i \frac{x_i - \mu}{\sigma^2} &amp;= 0 \\
\sum_i \frac{(x_i - \mu)^2}{\sigma^3} - \frac{N}{\sigma} = 0\end{split}\]</div>
<p>d’on podem concloure que l’EMV és:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\mu} &amp;= \bar{x} \\
\hat{\sigma} &amp;= \frac{1}{N}\sum_i (x_i - \bar{x})^2\end{split}\]</div>
<p>(noteu que <span class="math notranslate nohighlight">\(\hat{\sigma}\)</span> no és igual que <span class="math notranslate nohighlight">\(S_X^2\)</span>!)</p>
<p>És important tenir en compte que:</p>
<ol class="arabic simple">
<li><p>No sempre podrem calcular els EMV de manera analítica.</p></li>
<li><p>En alguns casos ho podrem calcular numèricament (fent servir el mètode de descens del gradient, o de Newton)</p></li>
<li><p>En alguns casos, l’EMV no serà únic (i.e. la log-versemblança tindrà més d’un màxim)</p></li>
<li><p>En molts casos la log-versemblança no serà concava, o diferenciable, per tant l’EMV pot ser computacionalment molt difícil de calcular</p></li>
</ol>
<p class="note">Malgrat aquestes limitacions, s’ha de reconèixer que la Màxima Versemblança
ens proporciona un mètode bastant genèric per trobar estimadors.</p>
</div>
<div class="section" id="exemple-emv-d-una-multinomial">
<h3><span class="section-number">4.1.3. </span>Exemple: EMV d’una multinomial<a class="headerlink" href="#exemple-emv-d-una-multinomial" title="Permalink to this headline">¶</a></h3>
<p>Continuem amb un parell més d’exemples d’aplicació del EMV.</p>
<p>Un model molt útil en estadística és el model <em>multinomial</em>, que
s’utilitza quan tenim observacions tabulades, per exemple: un histograma,
el nombre de respostes d’un qüestionari per edat de l’entrevistat,
l’incidència d’una malaltia per regió geogràfica, etc.</p>
<p>En tots aquests casos, es poden resumir les N observacions d’una mostra en un
vector <span class="math notranslate nohighlight">\(X_1, \cdots, X_M\)</span> on <span class="math notranslate nohighlight">\(X_i\)</span> es correspon amb el nombre d’observacions dins la casella <span class="math notranslate nohighlight">\(i\)</span>,
i hi ha M caselles i <span class="math notranslate nohighlight">\(\sum_i X_i = N\)</span>. <strong>Important</strong>: Noteu que en aquest cas <span class="math notranslate nohighlight">\(X_i\)</span> no és iid!</p>
<p>El model <em>multinomial</em> assumeix que la f.d.m. conjunta de <span class="math notranslate nohighlight">\(X_1, \cdots, X_M\)</span>
vé donada per:</p>
<div class="math notranslate nohighlight">
\[p(x_1, \cdots, x_m; p_1, \cdots, p_M) = \frac{N!}{\Pi_i {x_i!}}\Pi_i p_i^{x_i}\]</div>
<p>on <span class="math notranslate nohighlight">\(p_1, \cdots, p_M\)</span> són els paràmetres de la població, tals que <span class="math notranslate nohighlight">\(\sum_i p_i = 1\)</span>.</p>
<p>A partir d’aquesta f.d.m conjunta, i una mostra <span class="math notranslate nohighlight">\(X_1=x_1, \cdots, X_M=x_m\)</span>
podem calcular la log-versemblança:</p>
<div class="math notranslate nohighlight">
\[L( p_1, \cdots, p_M; x_1, \cdots, x_m) \propto - \sum_i \log (x_i!) + \sum_i x_i \log p_i\]</div>
<p>(on ignorem els termes que no depènen d’<span class="math notranslate nohighlight">\(x_i\)</span> o <span class="math notranslate nohighlight">\(p_i\)</span>.</p>
<p>Com que sabem que <span class="math notranslate nohighlight">\(\sum_i p_i = 1\)</span> , podem imposar la restricció que <span class="math notranslate nohighlight">\(p_M = 1 - \sum_{i=1}^{M-1} p_i\)</span>,
i tindrem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}L( p_1, \cdots, p_{M-1}; x_1, \cdots, x_m) \propto&amp;  - \sum_i \log (x_i!) + \sum_{i=1}^{M-1} x_i \log p_i \\
    &amp; + (N - \sum_{i=1}^{M-1} x_i ) \log (1 - \sum_{i=1}^{M-1} p_i)\end{split}\]</div>
<p>Calculant-ne el gradient i igualant-lo a 0 (exercici per casa), podrem concloure que l’EMV d’una multinomial és simplement:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_i = \frac{x_i}{N}\]</div>
<p class="note">En els exemples que hem vist fins ara (Gaussiana, Multinomial, Poisson..), excepte el model de precipitació a través d’una Gamma,
l’EMV es correspon amb l’estimador que hauriem escollit sense saber la teoria de Màxima Versemblança…
Val la pena complicar-nos la vida amb aquesta teoria!?</p>
</div>
<div class="section" id="exemple-emv-amb-dades-censurades">
<h3><span class="section-number">4.1.4. </span>Exemple: EMV amb dades censurades<a class="headerlink" href="#exemple-emv-amb-dades-censurades" title="Permalink to this headline">¶</a></h3>
<p>L’EMV és una metodologia molt més potent del que hem vist fins ara. D’na banda, com veurem tot seguit,
ens permet estimar paràmetres en casos on l’intuició potser ens fallaria. Per altra banda, com veurem
més endavant, els EMVs té unes propietats estadístiques interessants.</p>
<p>Considerem l’exemple següent: Estem interessats en modelar
la supervivència d’uns pacients sota un tractament mèdic determinat.
Considerem <span class="math notranslate nohighlight">\(X_i\)</span> l’edat en anys de defunció del pacient <span class="math notranslate nohighlight">\(i\)</span>.
Durant la durada del nostre estudi, alguns dels pacients moriran
però alguns altres seguiran vius. Per tant, per aquests últims
pacients l’únic que sabrem és que <span class="math notranslate nohighlight">\(X_i \geq e_i\)</span> on
<span class="math notranslate nohighlight">\(e_i\)</span> és l’edat del pacient en el moment d’acabar l’estudi.</p>
<p>Per tant necessitem modelar la versemblança d’una mostra
mixta d’observacions <span class="math notranslate nohighlight">\(X_i\)</span> i esdeveniments <span class="math notranslate nohighlight">\(X_j \geq e_j\)</span>,
on aquestes últimes s’anomenen “observacions censurades” (com
si algú ens hagués “censurat” les dades, en aquest cas l’univers).</p>
<p>Anomenem <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> el subconjunt
de pacients morts (i que per tant hem pogut observar-ne l’edat de defunció)
i <span class="math notranslate nohighlight">\(\bar{\mathcal{M}}\)</span> el subconjunt de pacients vius.</p>
<p>La funció de log-versemblança
que utilitzarem en aquest cas és:</p>
<div class="math notranslate nohighlight">
\[L(\theta) = \log P\left( \cap_{i: \mathcal{M}}{ X_i=x_i} \cap \cap_{i: \bar{\mathcal{M}}}{ X_i \geq e_i} \right)\]</div>
<p>Si la mostra és iid, això es simplificarà a:</p>
<div class="math notranslate nohighlight">
\[L(\theta) = \sum_{i: \mathcal{M}}\log p_X(x_i; \theta) + \sum_{i: \bar{\mathcal{M}}} \log(1 -  F_X(e_i; \theta))\]</div>
<p>on <span class="math notranslate nohighlight">\(p_X(x_i; \theta)\)</span> és la f.m.p. del nostre model d’edat de defunció i <span class="math notranslate nohighlight">\(F_X(e_i; \theta)\)</span> n’és la f.d.c. corresponent.</p>
<p>Suposem que modelem l’edat de defunció dels pacients segons una llei geomètrica:</p>
<div class="math notranslate nohighlight">
\[p_X(x; \rho) = (1 - \rho)^{x - 1} \rho\]</div>
<p>on <span class="math notranslate nohighlight">\(\rho\)</span> és el paràmetre de la població. La f.d.c. és :math:<a href="#id3"><span class="problematic" id="id4">`</span></a>F_x(x ;rho) = 1 - (1 -rho)^x `
i per tant podem calcular la log-versemblança com:</p>
<div class="math notranslate nohighlight">
\[L(\rho) =\]</div>
<p>Exercici: Calcular <span class="math notranslate nohighlight">\(\hat{\rho} = \arg \max  L(\rho)\)</span></p>
</div>
</div>
<div class="section" id="propietats-asimptotiques-de-l-emv">
<h2><span class="section-number">4.2. </span>Propietats asimptòtiques de l’EMV<a class="headerlink" href="#propietats-asimptotiques-de-l-emv" title="Permalink to this headline">¶</a></h2>
<div class="section" id="biaix-varianca-eqm-consistencia">
<h3><span class="section-number">4.2.1. </span>Biaix, Variança, EQM, Consistència<a class="headerlink" href="#biaix-varianca-eqm-consistencia" title="Permalink to this headline">¶</a></h3>
<p>Recordem del Tema 2 que els estimadors solen
ser funcions d’una mostra aleatòria, i que per tant
son en ells mateixos v.a.´s.</p>
<p>Per caracteritzar-los, doncs, haurem de fer servir
les eines que vem desenvolupar al Tema 2:</p>
<ul class="simple">
<li><p><strong>Biaix</strong>: <span class="math notranslate nohighlight">\(E\)</span></p></li>
<li><p>Variança</p></li>
<li><p>Error Quadràtic Mitjà</p></li>
</ul>
<p class="note">Quan l’EMV es correspon amb algun dels moments mostrals, com és el cas
dels EMVs per una família Gaussiana, de Poisson o Multinomial, podem
fer servir la teoria que vem derivar al Tema 2 per calcular-ne les propietats.</p>
<p>En general, però, l’EMV no tindra una forma analítica coneguda,
i serà difícil calcular-ne l’esperança, i molt més difícil
caracteritzar-ne la distribució.</p>
<p>La gran avantatge dels EMV és que, asimptòticament,
es poden caracteritzar bastant fàcilment.</p>
<p>Primer definim què és el que volem dir per “asimptòtic”.</p>
</div>
<div class="section" id="eficiencia-i-cota-de-cramer-rao">
<h3><span class="section-number">4.2.2. </span>Eficiència i Cota de Cramer-Rao<a class="headerlink" href="#eficiencia-i-cota-de-cramer-rao" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="intervals-de-confianca-per-emvs">
<h2><span class="section-number">4.3. </span>Intervals de confiança per EMVs<a class="headerlink" href="#intervals-de-confianca-per-emvs" title="Permalink to this headline">¶</a></h2>
<div class="section" id="intervals-asimptotics">
<h3><span class="section-number">4.3.1. </span>Intervals asimptòtics<a class="headerlink" href="#intervals-asimptotics" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="bootstrap-parametric">
<h3><span class="section-number">4.3.2. </span>Bootstrap paramètric<a class="headerlink" href="#bootstrap-parametric" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4. Tema 3: Estimació</a><ul>
<li><a class="reference internal" href="#estimacio-per-maxima-versemblanca">4.1. Estimació per Màxima Versemblança</a><ul>
<li><a class="reference internal" href="#ajust-de-distribucions-de-probabilitat">4.1.1. Ajust de distribucions de probabilitat</a></li>
<li><a class="reference internal" href="#calcul-de-l-emv">4.1.2. Càlcul de l’EMV</a></li>
<li><a class="reference internal" href="#exemple-emv-d-una-multinomial">4.1.3. Exemple: EMV d’una multinomial</a></li>
<li><a class="reference internal" href="#exemple-emv-amb-dades-censurades">4.1.4. Exemple: EMV amb dades censurades</a></li>
</ul>
</li>
<li><a class="reference internal" href="#propietats-asimptotiques-de-l-emv">4.2. Propietats asimptòtiques de l’EMV</a><ul>
<li><a class="reference internal" href="#biaix-varianca-eqm-consistencia">4.2.1. Biaix, Variança, EQM, Consistència</a></li>
<li><a class="reference internal" href="#eficiencia-i-cota-de-cramer-rao">4.2.2. Eficiència i Cota de Cramer-Rao</a></li>
</ul>
</li>
<li><a class="reference internal" href="#intervals-de-confianca-per-emvs">4.3. Intervals de confiança per EMVs</a><ul>
<li><a class="reference internal" href="#intervals-asimptotics">4.3.1. Intervals asimptòtics</a></li>
<li><a class="reference internal" href="#bootstrap-parametric">4.3.2. Bootstrap paramètric</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="0_2_Intro_stats.html"
                        title="previous chapter"><span class="section-number">3. </span>Tema 2: Introducció a l’inferència estadística</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="0_2_Intro_stats.html" title="3. Tema 2: Introducció a l’inferència estadística"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">104392 - Modelització i Inferència 2020.08.04 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href=""><span class="section-number">4. </span>Tema 3: Estimació</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Arnau Tibau Puig.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.2.1.
    </div>
  </body>
</html>