{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regla de Bayes i aplicació a la classificació de text\n",
    "\n",
    "En aquest pràctica introduïrem dos conceptes que no vem arribar a veure a les classes de teoria:\n",
    "\n",
    "* la regla de Bayes [Casella & Berger 1.3.5],\n",
    "* i la independència condicional\n",
    "\n",
    "i els aplicarem per desenvolupar un classificador de text binari (dues classes).\n",
    "\n",
    "La pràctica comença amb una mica de teoria, conté alguns exercicis de paper i llapis i finalment alguns exercicis computacionals. El codi el podeu desenvolupar en R o en Python, com us vingui millor. \n",
    "\n",
    "Els resultats dels exercicis els haureu d'entregar pel **dia 5/20/2020 abans de les 9:00**. Durant la classe d'aquest dia us en donaré la resolució.\n",
    "\n",
    "Recordeu que heu d'entregar el resultat de la pràctica per parelles (amb excepció d'algun triplet en cas de ser senars). No oblideu incloure el vostre Nom i NIU a la tramesa. \n",
    "\n",
    "## Regla de Bayes\n",
    "\n",
    "Donada una partició $A_1, A_2, \\cdots, A_N$ d'$\\Omega$, la regla de Bayes ens permet calcular la probabilitat d'un esdeveniment $A_i$ donat un altre esdeveniment $B$ com [Casella & Berger 1.3.5]:\n",
    "\n",
    "$P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{j=1}^NP(B|A_j)P(A_j)}$\n",
    "\n",
    "Normalment anomenarem:\n",
    "\n",
    "* $P(A_i|B)$ la probabilitat *posterior* d'$A_i$ havent observat $B$,\n",
    "* $P(B|A_i)$ la *versemblança* de B condicionat a $A_i$\n",
    "* $P(A_i)$ l'*a priori* d'$A_i$\n",
    "\n",
    "La fórmula és fàcil de demostrar a partir de l'identitat $P(A|B) P(B) = P(A \\cap B) = P(B|A) P(A)$.\n",
    "\n",
    "Vegem amb un exercici d'exemple l'importància d'aquesta fórmula.\n",
    "\n",
    "### Exercici 1\n",
    "\n",
    "Considereu un test mèdic per una certa patologia. El test té dos resultats possibles: $\\left\\{+, -\\right\\}$. Per altra banda, una persona d'una població pot tenir o no tenir la patologia, que denotarem per $\\left\\{\\mbox{Patologia}, \\overline{\\mbox{Patologia}}\\right\\}$.\n",
    "\n",
    "Suposem que el test no és perfecte i per tant comet errors. Per exemple:\n",
    "\n",
    "* $P(+ | \\overline{\\mbox{Patologia}}) = 0.1$ (fals positiu)\n",
    "* $P(- | {\\mbox{Patologia}}) = 0.05$ (fals negatiu)\n",
    "\n",
    "Per altra banda, sabem que la prevalència de la patologia en la població és molt baixa, posem\n",
    "$P({\\mbox{Patologia}}) = 0.001$. \n",
    "\n",
    "Si ens fem el test i ens dona positiu, quina és la probabilitat de que realment sofrim la patologia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sol.lució:\n",
    "\n",
    "$P(\\mbox{Patologia} | +) = \\frac{P(+ |\\mbox{Patologia})P(\\mbox{Patologia})}{P(+ |\\mbox{Patologia})P(\\mbox{Patologia}) + P(+ |\\overline{\\mbox{Patologia}})P(\\overline{\\mbox{Patologia}})} = \\frac{0.95 \\times 0.001}{0.95 \\times 0.001 + 0.1 \\times 0.999} = \\frac{0.00095}{0.10085} \\approx 0.009$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificació \n",
    "\n",
    "La regla de Bayes es pot fer servir per dissenyar classificadors. Per exemple, considereu els esdeveniments definits sobre una població de correus electrònics:\n",
    "\n",
    "* $A_1 = \\mbox{SPAM}$: El correu és spam (no desitjat)\n",
    "* $A_2 = \\mbox{HAM}$: El correu no és spam (també anomenat \"ham\")\n",
    "* $B$: L'esdeveniment corresponent a la presència o absència de $K$ certes paraules en el text del correu. Per exemple $B=W_1 \\cap W_2^c\\cap W_3$ es correspondria amb un correu el text del qual conté les paraules $W_1$ i $W_3$ i no conté la paraula $W_2$.\n",
    "\n",
    "Un classificador de correus electrònics és una funció que pren el text corresponent a $B$ i retorna $\\left\\{\\mbox{SPAM}, \\mbox{HAM}\\right\\}$. Considerem la següent funció:\n",
    "\n",
    "$f(B) = \\left\\{\\begin{array}{cc}\\mbox{SPAM} & \\mbox{ si } P(\\mbox{SPAM}|B) > P(\\mbox{HAM}|B) \\\\\\mbox{HAM} & \\mbox{altrament} \\end{array}\\right.$\n",
    "\n",
    "\n",
    "### Exercici 2\n",
    "\n",
    "Perquè té sentit una tal proposta?\n",
    "\n",
    "### Exercici 3\n",
    "\n",
    "En realitat, gràcies a la regla de Bayes, podem definir el nostre classificador en funció només del text del correu. Per fer-ho aplicarem la regla de Bayes a la definició de $f(B)$ per obtenir:\n",
    "\n",
    "$f(B) = \\left\\{\\begin{array}{cc}\\mbox{SPAM} & \\mbox{ si } P(B|\\mbox{SPAM})P(\\mbox{SPAM}) > P(B|\\mbox{HAM})P(\\mbox{HAM}) \\\\\\mbox{HAM} & \\mbox{altrament} \\end{array}\\right.$\n",
    "\n",
    "Anem a provar el nostre classificador. Per tal d'implementar-lo, hauriem de tenir coneixement de les quantitats $P(B|\\mbox{SPAM}), P(\\mbox{SPAM}), P(B|\\mbox{HAM}), P(\\mbox{HAM})$ per qualsevol B, que en principi no tenim. Per tant, les haurem d'**estimar** a partir de **dades d'entrenament** (*training data* en anglès).\n",
    "\n",
    "Per començar, ens imaginarem que volem classificar els correus només en funció de la presència o absència de dues paraules: \"prince\", \"USD\". L'esdeveniment $B$ per tant ens indica si alguna, cap, o totes aquestes paraules són presents en un determinat correu. Per exemple el correu amb text \"I am a Nigerian prince - send me 1000USD\" es correspon amb l'esdeveniment $B=\\mbox{prince} \\cap \\mbox{USD}$ i el text \"Hey dude - you still owe me 10USD!\" es correspon amb l'esdeveniment $B=\\mbox{prince}^c \\cap \\mbox{USD}$.\n",
    "\n",
    "Construïu un conjunt de dades d'entrenament \"de joguina\" amb 10 files. Us en dono dues d'exemple:\n",
    "\n",
    "|  Etiqueta | Correu                             |  \"prince\" | \"USD\"  |\n",
    "|-----------|------------------------------------|-----------|--------|\n",
    "|  $\\mbox{SPAM}$     | I am a Nigerian prince - send me 1000USD  |      1    |   1    |\n",
    "|  $\\overline{\\mbox{SPAM}}$  | Hey Arnau - how have you been?     |      0    |   0    |\n",
    "\n",
    "### Exercici 4\n",
    "\n",
    "Amb el vostre conjunt de dades, estimeu les quantitats $P(B|\\mbox{SPAM}), P(\\mbox{SPAM}), P(B|\\mbox{HAM}), P(\\mbox{HAM})$. *Pista*: L'estimador més simple de $P(B = \\mbox{prince}^c \\cap \\mbox{USD}^c|\\mbox{SPAM})$ seria\n",
    "\n",
    "$\\hat{P}(B = \\mbox{prince}^c \\cap \\mbox{USD}^c |\\mbox{SPAM}) = \\frac{\\mbox{# de correus amb etiqueta SPAM que no contenen \"prince\" ni \"USD\"}}{\\mbox{# de correus amb etiqueta SPAM}}$\n",
    "\n",
    "Fantàstic! Un cop ja teniu estimat $P(B|\\mbox{SPAM}), P(\\mbox{SPAM}), P(B|\\mbox{HAM}), P(\\mbox{HAM})$ ja teniu \"entrenat\" el vostre classificador de Bayes, que podeu fer servir amb qualsevol correu nou, només mirant si conté aquestes dues paraules clau. \n",
    "\n",
    "Creieu que el vostre serà un bon classificador? (Justifiqueu la resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificació per Bayes naïf\n",
    "\n",
    "El model que hem dissenyat fins ara és una mica limitat: tots ens podem imaginar varietats de correus de spam que no serien detectats pel nostre primer classificador (falsos negatius), o correus que no són spam que serien identificats com a tal (falsos positius). Això es deu en part al fet que fins ara només ens hem basat en dues paraules per prendre la nostra decisió.\n",
    "\n",
    "Sorprenentment però, l'idea bàsica que hem fet servir dona lloc a un classificador anomenat de Bayes Naïf, que fins fa relativament poc (10-15 anys) era competitiu respecte als millors classificadors d'aprentissatge automàtic per problemes d'aquest tipus.\n",
    "\n",
    "Considereu doncs el cas on volem construir el nostre classificador fent servir un vocabulari més ampli. El problema de fer servir un vocabulari més ampli és que haurem d'estimar $P(B|\\mbox{SPAM})$ i $P(B|\\mbox{HAM})$ per moltes possibles combinacions de $B$. \n",
    "\n",
    "### Exercici 5\n",
    "\n",
    "Si en l'exemple de l'Exercici 4, quan feiem servir 2 paraules, hem hagut d'estimar $P(B|\\mbox{SPAM})$ i $P(B|\\mbox{HAM})$ per les 4 possibles combinacions de B, si en fem servir $N$, per quantes combinacions ho haurem de fer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La naiveté\n",
    "\n",
    "La idea fonamental del mètode de Bayes Naïf és la utilització de la següent aproximació:\n",
    "\n",
    "$P\\left(B = \\cap_{i=1}^K W_i | A\\right) \\approx P(W_1|A)P(W_2|A)\\cdots P(W_K|A)$\n",
    "\n",
    "La igualtat seria certa només en el cas que els esdeveniments $W_i$ fóssin independents condicionals a $A$. (Si us pica la curiositat, podeu buscar un exemple d'esdeveniments $A_1$, $A_2$ que són independents condicionals a un tercer esdeveniment $B$, però no són independents.)\n",
    "\n",
    "Amb aquesta aproximació, enlloc d'haver d'estimar $P\\left(B = \\cap_{i=1}^K W_i | A\\right)$ (cosa complicada com hem vist en l'Exercici 5) només haurem d'estimar $P(W_1|A), P(W_2|A), \\cdots P(W_K|A)$. Per posar-ho en termes de l'exemple de l'Exercici 4, amb aquesta aproximació calculariem $\\hat{P}(B = \\mbox{prince}^c \\cap \\mbox{USD}^c |\\mbox{SPAM})$ com:\n",
    "\n",
    "$\\hat{P}(B = \\mbox{prince}^c \\cap \\mbox{USD}^c |\\mbox{SPAM}) = \\frac{\\mbox{# de correus SPAM que no contenen \"prince\" }}{\\mbox{# de correus SPAM}} \\times \\frac{\\mbox{# de correus SPAM que no contenen \"USD\" }}{\\mbox{# de correus SPAM}}$\n",
    "\n",
    "Som-hi doncs. Per aplicar aquest concepte, ens descarregarem un conjunt de dades de classificació de correus \"de veritat\". \n",
    "\n",
    "### Exercici 6\n",
    "\n",
    "\n",
    "1. Visiteu [aquesta pàgina i premeu \"Donwload\"](https://www.kaggle.com/venky73/spam-mails-dataset). Carregueu les dades amb pandas (o en la vostra llibreria preferida d'R), i exploreu-les: quants exemples tenim per cada classe (SPAM/HAM)? Quantes paraules hi ha en el text de cada correu? Quines són les paraules més comuns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('/Users/arnau.tibau/Downloads/spam_ham_dataset 2.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Separeu el conjunt de dades en un conjunt d'entrenament amb les 15000 primeres files i un de test amb les files restants. *NOTA*: normalment no és bona idea separar l'entrenament del test així, en aquest cas no tindrem cap problema perquè l'ordre de les dades és aleatori.\n",
    "\n",
    "*Pels següents exercicis, us he facilitat uns tests al final de l'anunciat perquè veieu quin és el comportament esperat de les funcions que haurem d'implementar. Us recomano fortament que per cada funció que implementeu, escrigueu una sèrie de **[tests unitaris](https://en.wikipedia.org/wiki/Unit_testing)** que comprovin que la funció es comporta com és esperat per una sèrie d'exemples.*\n",
    "\n",
    "3. Implementeu una funció `estimate_word_frequency(data, word)` que prengui com a input el conjunt de dades d'entrenament (`data`) i una cadena de caràcters `word`, i retorni la frequència de la paraula en cada classe (és a dir, un estimador de $P(\\mbox{word}|\\mbox{SPAM})$ i $P(\\mbox{word}|{\\mbox{HAM}})$ )\n",
    "4. Apliqueu aquest a funció a les paraules [\"Subject:\", \"company\", \"http\", \"information\", \"enron\", \"gas\", \"deal\", \"meter\", \"forwarded\"] i emmagatzemeu els resultats en un diccionary `word_frequencies` tal que per cada paraula hi teniu la seva frequència en SPAM i HAM.\n",
    "5. Implementeu la funció `estimate_spam_frequency(data)` que pren com a input el conjunt de dades i retorna una estimació de $P(\\mbox{SPAM})$.\n",
    "6. Implementeu una funció `estimate_likelihood(text, word_frequencies)` que pren com a input el text d'un correu (`text`), i l'estimació de freqüències de cada paraula (`word_frequencies`) i retorna una estimació de les versemblances $P(B|{\\mbox{SPAM}})$ i $P(B|\\mbox{HAM})$ fent servir l'aproximació de Bayes naïf.\n",
    "7. Implementeu la funció `naive_bayes(text, word_frequencies, spam_frequency)` que pren com a input el text d'un correu (`text`), l'estimació de la freqüència d'spam (`spam_frequency`) i l'estimació de freqüències de cada paraula (`word_frequencies`) i retorna 'SPAM' o 'HAM' en funció de la regla que hem definit a $f(B)$ (cf. \"Classificació\"), fent servir l'aproximació de Bayes Naïf. Per fer-ho, aprofiteu la funció `estimate_likelihood(text, word_frequencies)` que acabeu d'implementar. Us podria anar bé retornar també $P({\\mbox{SPAM}}|B)$, $P({\\mbox{HAM}}|B)$ per depurar la implementació.\n",
    "8. Proveu el vostre classificador amb alguns exemples del conjunt d'entrenament, i alguns del conjunt de test. Què tal funciona? Classifica algun exemple correctament? \n",
    "9. [OPCIONAL] Calculeu la precisió (*accuracy*) del vostre classificador.\n",
    "9. [OPCIONAL] Quin és el principal problema del vostre classificado? Què podriem fer per millorar-lo? Implementeu la millor i mireu si obteniu un guany en precisió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucions 3, 5, 6, 7\n",
    "def estimate_word_frequency(data, word):\n",
    "    word_freq = dict()\n",
    "    spam_data = data.loc[data.label=='spam']\n",
    "    word_freq['spam'] = spam_data.apply(lambda x: word in x.text, axis=1).sum()/spam_data.shape[0]\n",
    "    not_spam_data = data.loc[data.label=='ham'] \n",
    "    word_freq['ham'] = not_spam_data.apply(lambda x: word in x.text, axis=1).sum()/not_spam_data.shape[0]\n",
    "    return word_freq\n",
    "\n",
    "def estimate_spam_frequency(data):\n",
    "    return data.loc[data.label=='spam'].shape[0]/data.shape[0]\n",
    "\n",
    "def estimate_likelihood(text, word_frequencies):\n",
    "    p_b_given_spam = 1\n",
    "    p_b_given_ham = 1\n",
    "    words_found = 0\n",
    "    for word, freqs in word_frequencies.items():\n",
    "        if word in text:\n",
    "            p_b_given_spam = p_b_given_spam * freqs['spam']\n",
    "            p_b_given_ham = p_b_given_ham * freqs['ham']\n",
    "            words_found += 1\n",
    "    if words_found > 0:\n",
    "        return p_b_given_spam, p_b_given_ham\n",
    "    else:\n",
    "        return 0., 0.\n",
    "    \n",
    "def naive_bayes(text, word_frequencies, spam_frequency):\n",
    "    p_b_given_spam, p_b_given_ham = estimate_likelihood(text, word_frequencies)\n",
    "    if p_b_given_spam*spam_frequency > p_b_given_ham*(1-spam_frequency):\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comportament esperat de les funcions a implementar\n",
    "example_data = pd.DataFrame({\n",
    "    'label': ['spam', 'spam', 'ham', 'ham'],\n",
    "    'text': [\n",
    "        'A B C D',\n",
    "        'E F G C',\n",
    "        'A F G',\n",
    "        'C D E F'\n",
    "    ]\n",
    "})\n",
    "assert estimate_word_frequency(example_data, 'A') == {'spam': 1./2, 'ham': 1./2}\n",
    "assert estimate_word_frequency(example_data, 'B') == {'spam': 1./2, 'ham': 0}\n",
    "assert estimate_word_frequency(example_data, 'C') == {'spam': 1, 'ham': 1./2}\n",
    "\n",
    "\n",
    "assert estimate_spam_frequency(example_data) == 1./2\n",
    "\n",
    "word_frequencies = {\n",
    "    'A': {'spam': 1./2, 'ham': 1./2},\n",
    "    'B': {'spam': 1./2, 'ham': 0},\n",
    "    'C': {'spam': 1, 'ham': 1./2}\n",
    "}\n",
    "assert estimate_likelihood('A B', word_frequencies) == (1./4, 0)\n",
    "assert estimate_likelihood('A C', word_frequencies) == (1./2, 1./4)\n",
    "\n",
    "spam_frequency = estimate_spam_frequency(example_data)\n",
    "assert naive_bayes('B', word_frequencies, spam_frequency) == 'spam'\n",
    "assert naive_bayes('A B C', word_frequencies, spam_frequency) == 'spam'\n",
    "assert naive_bayes('F', word_frequencies, spam_frequency) == 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algunes funcions auxiliars que us podrien ser útils\n",
    "\n",
    "def word_count(text_list, min_char=3):\n",
    "    \"\"\"\n",
    "    Retorna el nombre de vegades que apareix cada paraula d'al menys `min_char`\n",
    "    caràcters a la llista de texts `text_list`\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    for text in text_list:\n",
    "        for word in text.split():\n",
    "            if len(word) < min_char:\n",
    "                continue\n",
    "            if word in counts:\n",
    "                counts[word] += 1\n",
    "            else:\n",
    "                counts[word] = 1\n",
    "            \n",
    "    return sorted(counts.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucions 8, 9\n",
    "training_data = dataset.head(15000)\n",
    "test_data = dataset.tail(5000)\n",
    "\n",
    "dictionary = [\"Subject:\", \"company\", \"http\", \"information\", \"enron\", \"gas\", \"deal\", \"meter\", \"forwarded\"] \n",
    "\n",
    "word_frequencies = {}\n",
    "for word in dictionary:\n",
    "    word_frequencies[word] = estimate_word_frequency(training_data, word)\n",
    "\n",
    "spam_frequency = estimate_spam_frequency(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.79      0.96      0.87      3552\n",
      "        spam       0.78      0.39      0.52      1448\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.79      0.67      0.70      5000\n",
      "weighted avg       0.79      0.79      0.77      5000\n",
      "\n",
      "accuracy: 0.7926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = test_data.text.apply(lambda text: naive_bayes(text, word_frequencies, spam_frequency))\n",
    "y_true = test_data.label\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print('accuracy:', accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, ['ham']*len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: re : e mail list for class\r\n",
      "please respond to great idea , byron !\r\n",
      "everybody ,\r\n",
      "i ' ve created a new moderated list at http : / / . listbot . com /\r\n",
      "if you are interested in hearing info ( from anyone , not just me ) about the\r\n",
      "bammel road young families class , please go to the address above to\r\n",
      "subscribe to the list .\r\n",
      "it ' s free .\r\n",
      "then , if you have anything that you want to share with the class , just\r\n",
      "e - mail it to @ listbot . com .\r\n",
      "- ram .\r\n",
      "- - - - - original message - - - - -\r\n",
      "from : byron w . ellis , cfp , clu , chfc [ mailto : byronellis @ usa . net ]\r\n",
      "sent : friday , march 30 , 2001 8 : 31 am\r\n",
      "to : ram tackett\r\n",
      "subject : e mail list for class\r\n",
      "what do you think about creating and maintaining an e mail address that will\r\n",
      "automatically send an e mail to everyone in our class ? that way anyone that\r\n",
      "wanted to blanket the class could always do so without going through you all\r\n",
      "the time .\r\n",
      "byron\r\n",
      "\" make all you can , save all you can , give all you can . \"\r\n",
      "john wesley\r\n",
      "byron w . ellis , cfp ? , clu , chfc\r\n",
      "senior financial advisor\r\n",
      "american express financial advisors\r\n",
      "ids life insurance company\r\n",
      "1450 lake robbins drive\r\n",
      "suite 100\r\n",
      "the woodlands , tx 77380\r\n",
      "phone 281 . 367 . 8658\r\n",
      "fax 281 . 364 . 9628\r\n",
      "e mail byronellis @ usa . net --> Predicted=spam True=ham\n",
      "Subject: re : lst rev feb . 2000 josey ranch nom\r\n",
      "daren i since you were at the offsite i went ahead and changed the volume\r\n",
      "down to 12 , 400 from 13 , 000 . --> Predicted=ham True=ham\n",
      "Subject: well head\r\n",
      "shoreline wants to increase the volume at meter 9830 for the 10 th gas day .\r\n",
      "this is a new meter so there is not much history to it . they want to go from\r\n",
      "535 to 750 . last month it flowed in the upper 500 ' s but it didn ' t come on\r\n",
      "till the 21 st of the month . --> Predicted=ham True=ham\n",
      "Subject: eastrans october first of the month nominations\r\n",
      "effective 10 / 1 / 00 deliveries to eastrans is 30 , 000 mmbtu / dy\r\n",
      "the redeliveries will be :\r\n",
      "7600 from fuels cotton valley\r\n",
      "22400 to pg & e --> Predicted=ham True=ham\n",
      "Subject: we have all your favorite programs at incredibly low prices\r\n",
      "windows x . p professi 0 nal update\r\n",
      "we might have just what you need :\r\n",
      "microsoft office x . p pro 2 oo 2 . . . . . . . . . . . . . . . . . loo dollars\r\n",
      "windows x . p pro 2 oo 2 . . . . . . . . . . . . . . 5 o dollars\r\n",
      "more information : http : / / bobztz . info / ? f 9 d 60 wd 5570 afo 803 a 5100 e 46 af 267 e 3\r\n",
      "we also have :\r\n",
      "adobe photoshop 8 . o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 o dollars\r\n",
      "corel draw 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 o dollars\r\n",
      "the offer is valid untill june 14 th\r\n",
      "stock is limited\r\n",
      "nice meeting you\r\n",
      "marlin keyes\r\n",
      "tinker\r\n",
      "haberman associates / the biopharmaceutical consortium , wayland , 01778 , united states of america\r\n",
      "phone : 941 - 151 - 7741\r\n",
      "mobile : 416 - 171 - 7172\r\n",
      "email : fwsnqbwwehr @ ipeg . com\r\n",
      "your reply to this confirmation message is not needed\r\n",
      "this shareware is a 89 second trial download\r\n",
      "notes :\r\n",
      "the contents of this message is for usage and should not be boa birch\r\n",
      "gemini country vanguard\r\n",
      "time : thu , 20 may 2004 11 : 03 : 07 + 0200\r\n",
      " --> Predicted=spam True=spam\n"
     ]
    }
   ],
   "source": [
    "for _, row in test_data.head().iterrows():\n",
    "    prediction = naive_bayes(row['text'], word_frequencies, spam_frequency)\n",
    "    print(f\"{row['text']} --> Predicted={prediction} True={row['label']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_in_prod",
   "language": "python",
   "name": "ml_in_prod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
